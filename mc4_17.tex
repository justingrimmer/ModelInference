\documentclass{beamer}

%\usepackage[table]{xcolor}
\mode<presentation> {
  \usetheme{Boadilla}
%  \usetheme{Pittsburgh}
%\usefonttheme[2]{sans}
\renewcommand{\familydefault}{cmss}
%\usepackage{lmodern}
%\usepackage[T1]{fontenc}
%\usepackage{palatino}
%\usepackage{cmbright}
  \setbeamercovered{transparent}
\useinnertheme{rectangles}
}
%\usepackage{normalem}{ulem}
%\usepackage{colortbl, textcomp}
\setbeamercolor{normal text}{fg=black}
\setbeamercolor{structure}{fg= black}
\definecolor{trial}{cmyk}{1,0,0, 0}
\definecolor{trial2}{cmyk}{0.00,0,1, 0}
\definecolor{darkgreen}{rgb}{0,.4, 0.1}
\newtheorem{prop}{Proposition}
\newtheorem{defn}{Definition}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}

\usefonttheme{professionalfonts} % using non standard fonts for beamer
\usefonttheme{serif}

\beamertemplatesolidbackgroundcolor{white}  \setbeamercolor{alerted
text}{fg=red}
\usepackage{multirow}

\setbeamertemplate{caption}[numbered]\newcounter{mylastframe}

%\begin{beamerboxesrounded}[upper=uppercol,lower=lowercol,shadow=true]{Block}
%$A = B$.
%\end{beamerboxesrounded}}
\renewcommand{\familydefault}{cmss}
\usepackage[all]{xy}
\usepackage{tikz}
\usetikzlibrary{arrows}
%\usepackage{palatino}
%\usepackage{eulervm}
\usecolortheme{lily}
%\usepackage[latin1]{inputenc}

\title[Methodology III] % (optional, nur bei langen Titeln n√∂tig)
{Political Methodology III: Model Based Inference}

\author{Justin Grimmer}
\institute[Stanford University]{Associate Professor\\Department of Political Science \\  Stanford University}
\vspace{0.3in}

\date{April 13th, 2017}

\begin{document}
\begin{frame}
\titlepage
\end{frame}


\begin{frame}

\scalebox{0.6}{\includegraphics{ObamaHealth.jpg}}

\end{frame}

\begin{frame}
\frametitle{Going Public (Franco, Grimmer, and Whang 2017)}

\begin{itemize}
\item[-] Presidents interrupt prime time coverage $\leadsto$ why? what effect?
\item[-] There are at least 6 explanations (Canes Wrone 2001, 2006) (others: credit claim, veto bargain, beauty contest, highlight obstruction, stupid)
\item[-] Gathered serendipitous surveys$\leadsto$ happen to be in field when presidents go public (before$\leadsto$ control; after $\leadsto$ treatment) (we also have social media data and newspapers)
\item[-] Does going public increase probability respondents identify topic of president's speech as salient problem?
\item[-] Do respondents identify it as most important problem?
\end{itemize}



\end{frame}






\begin{frame}
\frametitle{Modeling Bivariate Responses}

\begin{eqnarray}
Y_{i} & \in &  \{0, 1\} \nonumber \\
X_{i1} & = & \text{ Treatment status (0/1)}  \nonumber \\
X_{i2} & = & \text{Republican (0/1)} \nonumber
\end{eqnarray}

Infer effect of going public, condition on Republican as well  \\

\pause
\invisible<1>{\begin{tabular}{c|cc}
\hline
	& Control & Treat \\
\hline
$\bar{Y}$ & 0.373 & 0.367 \\
\hline
\end{tabular}
}


\end{frame}


\begin{frame}
\frametitle{Linear Probabilty Model}

\begin{eqnarray}
Y_{i} & \sim & \text{Normal}(\mu_{i}, \sigma^2)\nonumber \\
E[Y_{i}| X_{i}, \boldsymbol{\beta} ] & = & \beta_{0} + \beta_{1}X_{i1} + \beta_{2}X_{i2} \nonumber
\end{eqnarray}

\pause

\invisible<1>{$\beta_{1}  = $ Increase in the probability respondent $i$ identifies problem as most important problem.  } \pause

\invisible<1-2>{Issues:
\begin{itemize}
\item[1)] Predictions outside of 0 and 1
\item[2)] Constant effect
\item[3)] Efficiency loss
\end{itemize}
}
\end{frame}


\begin{frame}
\frametitle{Probit Model}

Suppose \\
$Y_{i} \sim \text{Bernoulli}(\pi_{i})$ \\

\pause
\invisible<1>{Assume:


\begin{eqnarray}
\tilde{Y}_{i} & \sim & \text{Normal}(\mu_{i}, 1) \nonumber \\} \pause
\invisible<1-2>{\tilde{Y}_{i} &  =  & \beta_{0} + \beta_{1}X_{i1} + \beta_{2} X_{i2} + \epsilon_{i} \nonumber \\} \pause
\invisible<1-3>{\epsilon_{i} & \sim & \text{Normal}(0, \alert{1}) \nonumber \\} \pause
\invisible<1-4>{Y_{i} & = & I(\tilde{Y}_{i}> 0) \nonumber } \pause
\end{eqnarray}

\invisible<1-5>{We will write:} \pause

\invisible<1-6>{$\boldsymbol{X}_{i} = (1, X_{i1}, X_{i2})$\\
$\boldsymbol{\beta} = (\beta_{0}, \beta_{1}, \beta_{2})$\\
$\boldsymbol{X}_{i} \boldsymbol{\beta} = \beta_{0} + \beta_{1} X_{i1} + \beta_{2}X_{i2}$}


\end{frame}


\begin{frame}
\frametitle{Probit Model}

\begin{eqnarray}
\pi_{i} = P(Y_{i} = 1 ) & = & P(\tilde{Y}_{i} > 0 ) \nonumber \pause \\
						\invisible<1>{& = & P(\beta_{0} + \beta_{1}X_{i1} + \beta_{2} X_{i2} + \epsilon_{i}> 0 ) \nonumber} \pause  \\
						\invisible<1-2>{& = & P(\epsilon_{i} > - \boldsymbol{X}_{i}^{'}\boldsymbol{\beta} )\nonumber} \pause  \\
						\invisible<1-3>{& = & P(\epsilon_{i} < \boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) \nonumber } \pause \\
						\invisible<1-4>{& = & \int_{-\infty}^{\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}} \phi(\epsilon_{i})d\epsilon_{i}  \nonumber } \pause \\
						\invisible<1-5>{& = & \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) \nonumber } \pause
\end{eqnarray}



\end{frame}

\begin{frame}

\begin{center}
\scalebox{0.5}{\includegraphics{NormCDF.pdf}}
\end{center}

\end{frame}


\begin{frame}
\frametitle{Probit Model}

\begin{eqnarray}
Y_{i} & \sim & \text{Bernoulli}(\pi_{i}) \nonumber \\
\pi_{i} & = & \Phi(\boldsymbol{X}^{'}\boldsymbol{\beta})\nonumber
\end{eqnarray}

\pause
\invisible<1>{Then our likelihood: } \pause
\begin{eqnarray}
\invisible<1-2>{L(\boldsymbol{\beta}|\boldsymbol{X}, \boldsymbol{Y} ) & = & f(\boldsymbol{Y}| \boldsymbol{X}, \boldsymbol{\beta}) \nonumber } \pause \\
\invisible<1-3>{& = & \prod_{i=1}^{N} f(Y_{i} | \boldsymbol{X}_{i} \boldsymbol{\beta}) \nonumber } \pause\\
\invisible<1-4>{& = & \prod_{i=1}^{N} \pi_{i}^{Y_{i}}(1 - \pi_{i})^{1- Y_{i}} \nonumber} \pause \\
\invisible<1-5>{& = & \prod_{i=1}^{N} \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})^{Y_{i}}(1 - \Phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}))^{1- Y_{i}} \nonumber }
\end{eqnarray}

\end{frame}

\begin{frame}
\frametitle{Probit Model}

\begin{eqnarray}
L(\boldsymbol{\beta}|\boldsymbol{X}, \boldsymbol{Y} ) & = & \prod_{i=1}^{N} \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})^{Y_{i}}(1 - \Phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}))^{1- Y_{i}} \nonumber  \pause \\
\invisible<1>{\log L(\boldsymbol{\beta}|\boldsymbol{X}, \boldsymbol{Y} ) & = & \sum_{i=1}^{N} \left( Y_{i} \log \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})  + (1- Y_{i} ) \log ( 1- \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})) \right)  \nonumber } \pause
\end{eqnarray}


\invisible<1-2>{Maximize likelihood with respect to $\boldsymbol{\beta}$}


\end{frame}



\begin{frame}
\frametitle{Probit Model}

\begin{eqnarray}
l(\boldsymbol{\beta}|\boldsymbol{X}, \boldsymbol{Y} ) & = & \sum_{i=1}^{N} \left( Y_{i} \log \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})  + (1- Y_{i} ) \log ( 1- \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})) \right)  \nonumber
\end{eqnarray}
\pause
\invisible<1>{Score Function for $\beta_{k}$:
\begin{eqnarray}
\frac{ \partial l(\boldsymbol{\beta}|\boldsymbol{X}_{i}, Y_{i}  )}{\partial \beta_{k} } & = & \left(Y_{i} \frac{\phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta} )}{\Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})} - (1-Y_{i}) \frac{\phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta} )}{1- \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta})}\right)X_{k} \nonumber
\end{eqnarray}} \pause

\invisible<1-2>{Hessian (typical entry $h_{kj}$): \\
\begin{eqnarray}
\frac{\partial^2 l(\boldsymbol{\beta}|\boldsymbol{X}_{i}, Y_{i}  )}{\partial \beta_{k} \partial \beta_{j} } & = & \phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}) [Y_{i} \frac{\phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}) +  \boldsymbol{X}_{i}\boldsymbol{\beta}\Phi(\boldsymbol{X}_{i} \boldsymbol{\beta}) }{\Phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta})^2} \nonumber \\
&& + (1 - Y_{i}) \frac{\phi(\boldsymbol{X}_{i} \boldsymbol{\beta}) - \boldsymbol{X}_{i}^{'} \boldsymbol{\beta}(1 - \Phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta} ) )}{( 1- \Phi(\boldsymbol{X}_{i}\boldsymbol{\beta} ))^2 } ]X_{ik}X_{ij}   \nonumber
\end{eqnarray}
}

\end{frame}




\begin{frame}
\frametitle{Probit Model}

Maximum Likelihood Estimates
\begin{eqnarray}
0 &= & \sum_{i=1}^{N} \left(Y_{i} \frac{\phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}^{*})}{\Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}^{*} )} - (1-Y_{i}) \frac{\phi(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}^{*} )}{1- \Phi(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}^{*})}\right)X_{k} \nonumber
\end{eqnarray}

Solve for $\boldsymbol{\beta}$?
\pause
\invisible<1>{Computational Approaches
\begin{itemize}
\item[-] Newton Raphson
\item[-] BFGS (Quasi-Newton.  Requires only an approximate Hessian.)
\end{itemize}

}
\end{frame}


\begin{frame}
\frametitle{Probit Model: Maximum Likelihood Estimates}

\textbf{R Code}


\end{frame}

\begin{frame}
\frametitle{Probit Model: Most Important Problem}

\begin{tabular}{ll}
	\hline
	& Most Important \\
	&  Problem \\
\hline
Intercept & -0.26  \\
		  & (0.03) \\
Post-Speech & -0.01 \\
			& (0.05) \\
Republican & -0.20 \\
			& (0.05) \\
\hline
\end{tabular}

How do we interpret the coefficients? \pause \\
\invisible<1>{\alert{They are on the latent scale}$\leadsto$ Need to define all values when determining predicted probabilities}

\end{frame}


\begin{frame}
\frametitle{Probit Model: Interpreting the Coefficients}


Expected Value: \pause
\begin{eqnarray}
\invisible<1>{E[Y_{i}| \boldsymbol{X}_{i} ] & = & \Phi(\beta_{0}^{*} + \beta_{1}^{*} X_{i1} + \beta_{2}^{*}X_{i2}) \nonumber \\} \pause
\invisible<1-2>{E[Y_{i} | X_{i1} = 0, X_{i2} = 0 ] & = & \Phi(-0.26 -0.01 \times 0 -0.20 \times 0 ) = 0.40 \nonumber \\} \pause
\invisible<1-3>{E[Y_{i} | X_{i1} = 0, X_{i2} = 1 ] & = & \Phi(-0.26 -0.01 \times 0 -0.20 \times 1 ) = 0.32 \nonumber } \pause
\end{eqnarray}

\invisible<1-4>{First difference: } \pause
\begin{eqnarray}
\invisible<1-5>{E[Y_{i} | X_{i1} = 1, X_{i2} = 0 ] - E[Y_{i} | X_{i1} = 0 , X_{i2} = 0 ] & = &  \nonumber \\
\Phi(-0.26 -0.01) - \Phi(-0.26) &  = &  -0.0039 \nonumber \\} \pause
\invisible<1-6>{E[Y_{i} | X_{i1} = 1, X_{i2} = 1 ] - E[Y_{i} | X_{i1} = 0 , X_{i2} = 1 ] & = &  \nonumber \\
\Phi(-0.26 -0.01 - 0.2) - \Phi(-0.26- 0.2) & = &  -0.0036 \nonumber } \pause
\end{eqnarray}

\invisible<1-7>{We will perform inference on these on Monday!}

\end{frame}

\begin{frame}
\frametitle{Probit Model: Interpreting the Coefficients}

\begin{eqnarray}
\frac{\partial \Phi(\boldsymbol{X}_{i} \boldsymbol{\beta} )}{\partial X_{ij}} & = & \phi(\boldsymbol{X}_{i} \beta)\beta_{j} \nonumber \\
\text{Max Effect} & = & 0.4 \times \beta_{j} \nonumber
\end{eqnarray}

\end{frame}


\begin{frame}
\frametitle{Logit Model}

Define:
\begin{eqnarray}
\text{Odds}(\pi) & = & \frac{\pi}{1- \pi} \nonumber \\
\log \text{Odds}(\pi) & = & \log\left( \frac{\pi}{1- \pi} \right)  \nonumber \\
\text{logit}(\pi) & \equiv & \log\left( \frac{\pi}{1- \pi} \right) \nonumber
\end{eqnarray}


\end{frame}


\begin{frame}
\frametitle{Logit Model}

\begin{eqnarray}
\log\left( \frac{\pi}{1- \pi} \right)& = & \alpha \nonumber \pause \\
\invisible<1>{\left(\frac{\pi}{1- \pi} \right) & = & \exp(\alpha) \nonumber \\}\pause
\invisible<1-2>{\pi & = & \exp(\alpha) (1- \pi) \nonumber \\} \pause
\invisible<1-3>{\pi(1 + \exp(\alpha)) &= & \exp(\alpha) \nonumber \\}\pause
\invisible<1-4>{\pi & = & \frac{\exp(\alpha)}{1+ \exp(\alpha)}  = \text{Logit}^{-1}(\alpha) \nonumber \\}\pause
\invisible<1-5>{\frac{\exp(\alpha)}{1+ \exp(\alpha)} & = & \frac{1}{1 + \exp(-\alpha)} =  \text{Logistic}(\alpha) \nonumber }
\end{eqnarray}


\end{frame}

\begin{frame}
\frametitle{Logit Model}

\only<1>{\scalebox{0.5}{\includegraphics{LogitFunc.pdf}}}
\only<2>{\scalebox{0.5}{\includegraphics{LogisticCDF.pdf}}}
\only<3>{\scalebox{0.5}{\includegraphics{LogistvsNormCDF.pdf}}}


\end{frame}


\begin{frame}

\begin{eqnarray}
Z & \sim & \text{Logistic}(\mu , s) \nonumber \pause \\
\invisible<1>{f(z) & = & \frac{\exp(\frac{z - \mu}{s})}{s (1 + \exp(\frac{z - \mu}{s}))^2} \nonumber\\}\pause
\invisible<1-2>{Z  & \sim & \underbrace{\text{Logistic}(0, 1) }_{\text{Standard Logistic}} \nonumber \\} \pause
\invisible<1-3>{f(z) & = & \frac{\exp(z) }{(1 + \exp(z))^2} \nonumber}
\end{eqnarray}


\end{frame}







\begin{frame}
\frametitle{Logit Model}

\begin{eqnarray}
\tilde{Y}_{i} & = & \boldsymbol{X}_{i}^{'} \boldsymbol{\beta}  + \epsilon_{i} \nonumber \\
\epsilon_{i} & \sim & \text{Logistic}(0, 1) \nonumber \\\pause
\invisible<1>{P(Y_{i} = 1|\boldsymbol{X}_{i}, \boldsymbol{\beta})  & = & I(\tilde{Y}_{i} > 0  )\nonumber \\} \pause
\invisible<1-2>{      & = & I(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta} + \epsilon_{i} > 0) \nonumber \\} \pause
\invisible<1-3>{	  & = & I(\epsilon_{i}> - \boldsymbol{X}_{i}^{'}\boldsymbol{\beta} ) \nonumber \\} \pause
\invisible<1-4>{	  & = & I(\epsilon_{i} < \boldsymbol{X}_{i}^{'}\boldsymbol{\beta} ) \nonumber \\} \pause
\invisible<1-5>{	  & = & \text{Logistic}(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) = F(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) \nonumber }
\end{eqnarray}

\end{frame}

\begin{frame}
\frametitle{Logit Model}

\begin{eqnarray}
Y_{i} & \sim & \text{Bernoulli}(\pi_{i}) \nonumber \\
\pi_{i} & = & F(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) \nonumber
\end{eqnarray}

Likelihood function
\begin{eqnarray}
L(\boldsymbol{\beta}| \boldsymbol{X}, \boldsymbol{Y}) & = & f(\boldsymbol{Y}| \boldsymbol{X}, \boldsymbol{\beta}) \nonumber \\
& = & \prod_{i=1}^{N} f(Y_{i} | \boldsymbol{X}_{i}, \boldsymbol{\beta}) \nonumber \\
& = & \prod_{i=1}^{N} F(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta})^{Y_{i}} (1 - F(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta}))^{1-Y_{i}} \nonumber
\end{eqnarray}


\end{frame}

\begin{frame}
\frametitle{Logit Model}

Log-likelihood:
\begin{eqnarray}
l(\boldsymbol{\beta}| \boldsymbol{X}, \boldsymbol{Y}) & = & \sum_{i=1}^{N} Y_{i} \log F(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta}) + (1- Y_{i}) \log(1- F(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta})) \nonumber
\end{eqnarray}

Homework:
Derive Score + Hessian for Logistic Normal + Implement with Optim


\end{frame}


\begin{frame}

\textbf{R Code}

\end{frame}

\begin{frame}
\frametitle{Logit Model: Most Important Problem}

Most Important Problem

\begin{tabular}{lll}
	\hline
	&  Probit & Logit\\
\hline
Intercept & -0.26  & -0.41 \\
		  & (0.03) & (0.05)\\
Post-Speech & -0.01 & -0.02\\
			& (0.05) & (0.09) \\
Republican & -0.20   &  -0.32\\
			& (0.05)  &  (0.08) \\
\hline
\end{tabular}
\end{frame}


\begin{frame}
\frametitle{Logit Model: Interpreting the Coefficients}

Expected Value: \pause
\begin{eqnarray}
\invisible<1>{E[Y_{i}| \boldsymbol{X}_{i} ] & = & \frac{1}{ 1+ \exp(-\beta_{0} - \beta_{1} X_{i1} - \beta_{2} X_{i2})  } \nonumber \\} \pause
\invisible<1-2>{E[Y_{i}| X_{i1} =0, X_{i2} = 0 ] & = & \frac{1}{1 + \exp(0.41)} = 0.40 \nonumber \\} \pause
\invisible<1-3>{E[Y_{i}| X_{i1}  = 0, X_{i2} =1 ] & = & \frac{1}{ 1+ \exp(0.41 + 0.32)} = 0.33 \nonumber } \pause
\end{eqnarray}

\invisible<1-4>{First Differences} \pause
\begin{eqnarray}
\invisible<1-5>{E[Y_{i} | X_{i1} = 1, X_{i2} = 0 ] - E[Y_{i} | X_{i1} = 0, X_{i2} = 0 ]& = & \nonumber \\
0.3941 - 0.3989 & = &  -0.005 \nonumber \\} \pause
\invisible<1-6>{E[Y_{i} | X_{i1} = 1, X_{i2} = 1 ] - E[Y_{i} | X_{i1} = 0, X_{i2} = 1 ]& = &  \nonumber \\
0.3208 - 0.32519	&= & -0.0043 \nonumber }
\end{eqnarray}

\end{frame}

\begin{frame}
\frametitle{Logit Model: Interpreting the Coefficients}

\begin{eqnarray}
\frac{\partial F(\boldsymbol{X}_{i}^{'}\boldsymbol{\beta} ) }{\partial X_{ij}  } & = & f(\boldsymbol{X}_{i}^{'} \boldsymbol{\beta})\beta_{j} \nonumber \\
\text{Max Effect} & = & 0.25 \times \beta_{j} \nonumber
\end{eqnarray}


\end{frame}


\begin{frame}
\frametitle{Most Important Problem: Linear Probability Model}

\begin{tabular}{llll}
	\hline
	&  Probit & Logit & LPM \\
\hline
Intercept & -0.26  & -0.41 & 0.40 \\
		  & (0.03) & (0.05) & (0.13) \\
Post-Speech & -0.01 & -0.02 & -0.004\\
			& (0.05) & (0.09) & (0.02) \\
Republican & -0.20   &  -0.32 & -0.07\\
			& (0.05)  &  (0.08) & (0.02) \\
\hline
\end{tabular}

LPM might (usually) be ok, but
\begin{itemize}
\item[1)] Probit/Logit  = easy to run
\item[2)] Base for more complicated models
\end{itemize}

\end{frame}





\end{document}
